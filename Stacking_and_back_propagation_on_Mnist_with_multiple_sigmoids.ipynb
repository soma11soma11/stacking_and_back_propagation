{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking and back propagation on Mnist with multiple sigmoids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "mnist = fetch_mldata('MNIST original', data_home=\".\")\n",
    "mnist.data, mnist.target = shuffle(mnist.data, mnist.target)\n",
    "X = mnist.data\n",
    "y_float = mnist.target\n",
    "y_int = y_float.astype(np.int64)\n",
    "y = np.eye(10)[y_int]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "rf_train = clf.predict(X_train)\n",
    "rf_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add 1 to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_train = np.ones(X_train.shape[0])\n",
    "X_train = np.hstack((X_train, rf_train, s_train.reshape(len(s_train),1)))\n",
    "s_test = np.ones(X_test.shape[0])\n",
    "X_test = np.hstack((X_test, rf_test, s_test.reshape(len(s_test),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52500, 795)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "# n_batches = 100\n",
    "# inc_pca = IncrementalPCA(n_components = 154)\n",
    "# for X_batch in np.array_split(X_train, n_batches):\n",
    "#     inc_pca.partial_fit(X_batch)\n",
    "    \n",
    "# X_reduced_train = inc_pca.transform(X_train)\n",
    "# X_reduced_train = np.hstack((X_reduced_train, s_train.reshape(len(s_train),1)))\n",
    "# X_reduced_test = inc_pca.transform(X_test)\n",
    "# X_reduced_test = np.hstack((X_reduced_test, s_test.reshape(len(s_test),1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_output_z1(x, w1):\n",
    "    z1 = np.dot(x, w1)\n",
    "    return z1\n",
    "\n",
    "def logistic_output_z2(x, w2):\n",
    "    z2 = sigmoid(np.dot(x, w2))\n",
    "    return z2\n",
    "\n",
    "def sigmoid(a):\n",
    "    return 1.0 / (1.0 + np.exp(-a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_output(x, z1, z2, theta1, theta2, theta3):\n",
    "    zf = np.matmul(z1, theta1) + np.matmul(z2, theta2) + np.array(np.dot(x, theta3))\n",
    "    return zf\n",
    "\n",
    "def gradient_c_theta1(z1, zf, y):\n",
    "    gradient = np.matmul(np.transpose(z1), (sigmoid(zf)-y)) / N\n",
    "    return gradient\n",
    "\n",
    "def gradient_c_theta2(z2, zf, y):\n",
    "    gradient = np.matmul(np.transpose(z2), (sigmoid(zf)-y)) / N\n",
    "    return gradient\n",
    "\n",
    "def gradient_c_theta3(x, zf, y):\n",
    "    gradient = np.matmul(np.transpose(x), (sigmoid(zf)-y)) / N\n",
    "    return gradient\n",
    "\n",
    "def gradient_c_w1(x, theta1, zf, y):\n",
    "    gradient = np.matmul(np.transpose(x), np.transpose(np.matmul(theta1, np.transpose(np.array((sigmoid(zf) - y)))))) / N\n",
    "    return gradient\n",
    "\n",
    "def gradient_c_w2(x, w2, theta2, zf, y):\n",
    "    elemsig = sigmoid(np.matmul(x, w2)) # [5000, 1]\n",
    "    elem1=np.transpose(np.array(sigmoid(zf) - y)) # [10,5000]\n",
    "    elem2=np.matmul(theta2, elem1) # [1, 5000]\n",
    "    elem3=np.matmul(np.transpose(elemsig), np.transpose(elem2)) # [1,1]\n",
    "    elem4 = np.matmul(elemsig, (1 - elem3)) # [5000,1]\n",
    "    gradient= np.matmul(np.transpose(x), elem4)/ N # [785,1]\n",
    "\n",
    "    return gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z1 = linear_output_z1(X_train, int_w1)\n",
    "# z2 = logistic_output_z2(X_train, int_w2)\n",
    "# zf = logistic_output(X_train, z1, z2, int_theta1, int_theta2, int_theta3)\n",
    "\n",
    "# elemsig = sigmoid(np.matmul(X_train, int_w2)) # [52500, 2]\n",
    "# elem1=np.transpose(np.array(sigmoid(zf) - y_train)) # [10,52500]\n",
    "# elem2=np.matmul(int_theta2, elem1) # [2, 52500]\n",
    "# elem3=np.matmul(np.transpose(elemsig), np.transpose(elem2)) # [2,2]\n",
    "# elem4 = np.matmul(elemsig, (1 - elem3)) # [5000,1]\n",
    "# # gradient= np.matmul(np.transpose(x), elem4)/ N # [785,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, int_w1, int_w2, int_theta1, int_theta2, int_theta3, lowtrain, uptrain, iterations):\n",
    "\n",
    "    place_w1=int_w1\n",
    "    place_w2=int_w2\n",
    "    place_theta1=int_theta1\n",
    "    place_theta2=int_theta2\n",
    "    place_theta3=int_theta3\n",
    "\n",
    "    for i in range(iterations):\n",
    "        trainrate=np.random.uniform(lowtrain,uptrain,1)/np.cbrt(i+1) \n",
    "        z1 = linear_output_z1(x, place_w1)\n",
    "        z2 = logistic_output_z2(x, place_w2)\n",
    "        zf = logistic_output(x, z1, z2, place_theta1, place_theta2, place_theta3)\n",
    "        p = sigmoid(zf)\n",
    "\n",
    "        gradient_theta1 = gradient_c_theta1(z1, zf, y)\n",
    "        gradient_theta2 = gradient_c_theta2(z2, zf, y)\n",
    "        gradient_theta3 = gradient_c_theta3(x, zf, y)\n",
    "        gradient_w1 = gradient_c_w1(x, place_theta1, zf, y)\n",
    "        gradient_w2 = gradient_c_w2(x, place_w2, place_theta2, zf, y)\n",
    "        \n",
    "            \n",
    "        place_w1 = place_w1 - (trainrate * gradient_w1) - (0.1/N)*place_w1 * trainrate\n",
    "        place_w2 = place_w2 - (trainrate * gradient_w2) - (0.1/N)*place_w2 * trainrate\n",
    "        place_theta1 = place_theta1 - trainrate*gradient_theta1*0.01 - (0.1/N)*place_theta1 * trainrate \n",
    "        place_theta2 = place_theta2 - trainrate*gradient_theta2 - (0.1/N)*place_theta2 * trainrate\n",
    "        place_theta3 = place_theta3 - trainrate*gradient_theta3 - (0.1/N)*place_theta3 * trainrate\n",
    "\n",
    "    \n",
    "    return  p, place_theta1, place_theta2, place_theta3, place_w1, place_w2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in exp\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "N_linear = 3\n",
    "M_logistic = 3\n",
    "\n",
    "int_w1, int_w2 = np.random.uniform(-1,1,(X_train.shape[1],N_linear)), np.random.uniform(-1,1,(X_train.shape[1], M_logistic))\n",
    "int_theta1, int_theta2, int_theta3 = np.random.uniform(-1,1,(N_linear,10)), np.random.uniform(-1,1,(M_logistic,10)),np.random.uniform(-1,1,(X_train.shape[1],10))\n",
    "result = gradient_descent(X_train, y_train, int_w1, int_w2, int_theta1, int_theta2, int_theta3, 0.00001, 0.0001, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_accuracy(xtest, ytest, theta1, theta2, theta3, w1, w2):\n",
    "    z1 = linear_output_z1(xtest, w1)\n",
    "    z2 = logistic_output_z2(xtest, w2)\n",
    "    zf = logistic_output(xtest, z1, z2, theta1, theta2, theta3)\n",
    "    p = sigmoid(zf)\n",
    "    prediction = np.argmax(p, axis=1)\n",
    "    answer = np.argmax(ytest, axis=1)\n",
    "    success_rate = answer == prediction\n",
    "    success_rate = success_rate*1\n",
    "    prediction_rate = sum(success_rate) / xtest.shape[0]\n",
    "    \n",
    "    return prediction_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in exp\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.800971428571\n",
      "0.800628571429\n",
      "0.8012\n",
      "0.801142857143\n",
      "0.800971428571\n",
      "0.8012\n",
      "0.801771428571\n",
      "0.801028571429\n",
      "0.801771428571\n",
      "0.801428571429\n",
      "0.801885714286\n",
      "0.8012\n",
      "0.802228571429\n",
      "0.801942857143\n",
      "0.802114285714\n",
      "0.801942857143\n",
      "0.802\n",
      "0.802057142857\n",
      "0.802571428571\n",
      "0.803485714286\n",
      "0.802742857143\n",
      "0.801942857143\n",
      "0.802571428571\n",
      "0.8032\n",
      "0.802857142857\n",
      "0.802342857143\n",
      "0.8028\n",
      "0.803028571429\n",
      "0.803714285714\n",
      "0.803657142857\n",
      "0.803542857143\n",
      "0.803657142857\n",
      "0.8032\n",
      "0.802971428571\n",
      "0.803371428571\n",
      "0.803942857143\n",
      "0.803885714286\n",
      "0.8044\n",
      "0.803828571429\n",
      "0.803942857143\n",
      "0.804228571429\n",
      "0.804457142857\n",
      "0.804971428571\n",
      "0.804685714286\n",
      "0.804742857143\n",
      "0.804742857143\n",
      "0.804514285714\n",
      "0.803542857143\n",
      "0.803828571429\n",
      "0.804114285714\n",
      "0.804114285714\n",
      "0.804228571429\n",
      "0.804171428571\n",
      "0.804628571429\n",
      "0.804057142857\n",
      "0.803428571429\n",
      "0.802971428571\n",
      "0.803371428571\n",
      "0.803428571429\n",
      "0.803314285714\n",
      "0.803028571429\n",
      "0.803828571429\n",
      "0.803942857143\n",
      "0.8032\n",
      "0.803771428571\n",
      "0.8044\n",
      "0.804457142857\n",
      "0.804514285714\n",
      "0.804742857143\n",
      "0.8048\n",
      "0.804742857143\n",
      "0.805028571429\n",
      "0.804857142857\n",
      "0.8056\n",
      "0.805028571429\n",
      "0.804342857143\n",
      "0.805257142857\n",
      "0.805142857143\n",
      "0.804857142857\n",
      "0.804514285714\n",
      "0.804914285714\n",
      "0.805485714286\n",
      "0.805714285714\n",
      "0.805542857143\n",
      "0.805771428571\n",
      "0.805485714286\n",
      "0.8056\n",
      "0.805085714286\n",
      "0.806457142857\n",
      "0.8056\n",
      "0.805485714286\n",
      "0.8056\n",
      "0.805885714286\n",
      "0.805657142857\n",
      "0.806114285714\n",
      "0.8056\n",
      "0.806057142857\n",
      "0.807142857143\n",
      "0.806171428571\n",
      "0.805371428571\n",
      "0.805714285714\n",
      "0.805428571429\n",
      "0.805657142857\n",
      "0.806057142857\n",
      "0.805771428571\n",
      "0.806742857143\n",
      "0.807485714286\n",
      "0.8076\n",
      "0.806857142857\n",
      "0.807028571429\n",
      "0.807428571429\n",
      "0.806742857143\n",
      "0.807657142857\n",
      "0.807085714286\n",
      "0.806457142857\n",
      "0.806171428571\n",
      "0.807085714286\n",
      "0.807257142857\n",
      "0.807828571429\n",
      "0.807942857143\n",
      "0.807085714286\n",
      "0.807485714286\n",
      "0.807257142857\n",
      "0.807485714286\n",
      "0.808457142857\n",
      "0.8076\n",
      "0.808057142857\n",
      "0.8076\n",
      "0.807542857143\n",
      "0.807828571429\n",
      "0.808285714286\n",
      "0.808457142857\n",
      "0.807885714286\n",
      "0.807714285714\n",
      "0.808\n",
      "0.807942857143\n",
      "0.807085714286\n",
      "0.807828571429\n",
      "0.808457142857\n",
      "0.8072\n",
      "0.808057142857\n",
      "0.808228571429\n",
      "0.808571428571\n",
      "0.808857142857\n",
      "0.809257142857\n",
      "0.808971428571\n",
      "0.808628571429\n",
      "0.8088\n",
      "0.809371428571\n",
      "0.809371428571\n",
      "0.808514285714\n",
      "0.808971428571\n",
      "0.8088\n",
      "0.8092\n",
      "0.808228571429\n",
      "0.808914285714\n",
      "0.809542857143\n",
      "0.809542857143\n",
      "0.810742857143\n",
      "0.811028571429\n",
      "0.809885714286\n",
      "0.810514285714\n",
      "0.810057142857\n",
      "0.808857142857\n",
      "0.809314285714\n",
      "0.809828571429\n",
      "0.809542857143\n",
      "0.810285714286\n",
      "0.810171428571\n",
      "0.809828571429\n",
      "0.809828571429\n",
      "0.809542857143\n",
      "0.810114285714\n",
      "0.81\n",
      "0.810457142857\n",
      "0.81\n",
      "0.809771428571\n",
      "0.809885714286\n",
      "0.809714285714\n",
      "0.810628571429\n",
      "0.810857142857\n",
      "0.812\n",
      "0.811542857143\n",
      "0.810114285714\n",
      "0.810114285714\n",
      "0.811371428571\n",
      "0.810685714286\n",
      "0.811314285714\n",
      "0.810628571429\n",
      "0.811257142857\n",
      "0.811885714286\n",
      "0.811142857143\n",
      "0.810285714286\n",
      "0.811028571429\n",
      "0.811028571429\n",
      "0.810057142857\n",
      "0.8104\n",
      "0.810857142857\n",
      "0.810971428571\n",
      "0.8104\n",
      "0.811257142857\n",
      "0.811142857143\n",
      "0.810971428571\n",
      "0.811371428571\n",
      "0.811428571429\n",
      "0.811142857143\n",
      "0.811371428571\n",
      "0.811028571429\n",
      "0.810457142857\n",
      "0.810857142857\n",
      "0.810514285714\n",
      "0.810971428571\n",
      "0.810571428571\n",
      "0.811085714286\n",
      "0.811542857143\n",
      "0.811371428571\n",
      "0.811542857143\n",
      "0.8116\n",
      "0.810971428571\n",
      "0.811657142857\n",
      "0.811257142857\n",
      "0.811942857143\n",
      "0.811657142857\n",
      "0.811828571429\n",
      "0.813257142857\n",
      "0.812628571429\n",
      "0.812457142857\n",
      "0.812114285714\n",
      "0.812571428571\n",
      "0.812685714286\n",
      "0.812171428571\n",
      "0.811942857143\n",
      "0.811371428571\n",
      "0.811771428571\n",
      "0.812057142857\n",
      "0.8124\n",
      "0.8128\n",
      "0.813142857143\n",
      "0.813828571429\n",
      "0.813942857143\n",
      "0.813257142857\n",
      "0.812342857143\n",
      "0.811942857143\n",
      "0.813771428571\n",
      "0.813028571429\n",
      "0.813257142857\n",
      "0.813542857143\n",
      "0.813885714286\n",
      "0.8132\n",
      "0.812971428571\n",
      "0.812171428571\n",
      "0.813771428571\n",
      "0.813485714286\n",
      "0.813542857143\n",
      "0.812342857143\n",
      "0.813257142857\n",
      "0.813485714286\n",
      "0.812742857143\n",
      "0.813428571429\n",
      "0.8132\n",
      "0.813657142857\n",
      "0.814285714286\n",
      "0.814342857143\n",
      "0.8144\n",
      "0.8136\n",
      "0.813771428571\n",
      "0.814228571429\n",
      "0.8144\n",
      "0.8144\n",
      "0.813885714286\n",
      "0.812342857143\n",
      "0.813828571429\n",
      "0.813828571429\n",
      "0.814571428571\n",
      "0.814571428571\n",
      "0.815542857143\n",
      "0.814742857143\n",
      "0.814914285714\n",
      "0.814514285714\n",
      "0.815028571429\n",
      "0.8152\n",
      "0.815885714286\n",
      "0.816114285714\n",
      "0.815885714286\n",
      "0.815028571429\n",
      "0.8144\n",
      "0.815314285714\n",
      "0.815942857143\n",
      "0.816228571429\n",
      "0.815657142857\n",
      "0.815542857143\n",
      "0.815142857143\n",
      "0.814114285714\n",
      "0.814342857143\n",
      "0.814171428571\n",
      "0.815942857143\n",
      "0.815428571429\n",
      "0.815428571429\n",
      "0.816114285714\n",
      "0.816342857143\n",
      "0.816\n",
      "0.816114285714\n",
      "0.815828571429\n",
      "0.815657142857\n",
      "0.815485714286\n",
      "0.816228571429\n",
      "0.815257142857\n",
      "0.815371428571\n",
      "0.815771428571\n",
      "0.815542857143\n",
      "0.815085714286\n",
      "0.816114285714\n",
      "0.816514285714\n",
      "0.816571428571\n",
      "0.816285714286\n",
      "0.816285714286\n",
      "0.816685714286\n",
      "0.816628571429\n",
      "0.816857142857\n",
      "0.816971428571\n",
      "0.817314285714\n",
      "0.817428571429\n",
      "0.8168\n",
      "0.817485714286\n",
      "0.816742857143\n",
      "0.815828571429\n",
      "0.816057142857\n",
      "0.816228571429\n",
      "0.815657142857\n",
      "0.8152\n",
      "0.815657142857\n",
      "0.8152\n",
      "0.816457142857\n",
      "0.816285714286\n",
      "0.816857142857\n",
      "0.817028571429\n",
      "0.816285714286\n",
      "0.816628571429\n",
      "0.816514285714\n",
      "0.814971428571\n",
      "0.814\n",
      "0.815657142857\n",
      "0.816\n",
      "0.815885714286\n",
      "0.815657142857\n",
      "0.815828571429\n",
      "0.816742857143\n",
      "0.816114285714\n",
      "0.816857142857\n",
      "0.817314285714\n",
      "0.8172\n",
      "0.817314285714\n",
      "0.817257142857\n",
      "0.817771428571\n",
      "0.817714285714\n",
      "0.818\n",
      "0.817714285714\n",
      "0.817828571429\n",
      "0.818\n",
      "0.818114285714\n",
      "0.817828571429\n",
      "0.817371428571\n",
      "0.817085714286\n",
      "0.817771428571\n",
      "0.817428571429\n",
      "0.817714285714\n",
      "0.817885714286\n",
      "0.817485714286\n",
      "0.817028571429\n",
      "0.8172\n",
      "0.8176\n",
      "0.818114285714\n",
      "0.818057142857\n",
      "0.817771428571\n",
      "0.817771428571\n",
      "0.818571428571\n",
      "0.8184\n",
      "0.818057142857\n",
      "0.817942857143\n",
      "0.817542857143\n",
      "0.817942857143\n",
      "0.818342857143\n",
      "0.818514285714\n",
      "0.817942857143\n",
      "0.817771428571\n",
      "0.817314285714\n",
      "0.817657142857\n",
      "0.8168\n",
      "0.816857142857\n",
      "0.817371428571\n",
      "0.818685714286\n",
      "0.818857142857\n",
      "0.818457142857\n",
      "0.818342857143\n",
      "0.819028571429\n",
      "0.818628571429\n",
      "0.818171428571\n",
      "0.818457142857\n",
      "0.818\n",
      "0.817657142857\n",
      "0.818\n",
      "0.8196\n",
      "0.819257142857\n",
      "0.818914285714\n",
      "0.818514285714\n",
      "0.819257142857\n",
      "0.818457142857\n",
      "0.817942857143\n",
      "0.8188\n",
      "0.818914285714\n",
      "0.818457142857\n",
      "0.819028571429\n",
      "0.818914285714\n",
      "0.818171428571\n",
      "0.8184\n",
      "0.818514285714\n",
      "0.819028571429\n",
      "0.818857142857\n",
      "0.819314285714\n",
      "0.818685714286\n",
      "0.819314285714\n",
      "0.8192\n",
      "0.819657142857\n",
      "0.82\n",
      "0.818228571429\n",
      "0.8184\n",
      "0.817828571429\n",
      "0.818\n",
      "0.8172\n",
      "0.818057142857\n",
      "0.817428571429\n",
      "0.818171428571\n",
      "0.8176\n",
      "0.818\n",
      "0.818685714286\n",
      "0.818\n",
      "0.82\n",
      "0.819657142857\n",
      "0.819542857143\n",
      "0.819885714286\n",
      "0.819028571429\n",
      "0.818742857143\n",
      "0.818685714286\n",
      "0.8192\n",
      "0.818628571429\n",
      "0.818742857143\n",
      "0.8188\n",
      "0.818857142857\n",
      "0.819371428571\n",
      "0.819428571429\n",
      "0.819885714286\n",
      "0.8196\n",
      "0.819942857143\n",
      "0.820228571429\n",
      "0.819542857143\n",
      "0.8188\n",
      "0.819257142857\n",
      "0.819714285714\n",
      "0.819885714286\n",
      "0.820057142857\n",
      "0.820514285714\n",
      "0.821142857143\n",
      "0.821028571429\n",
      "0.820342857143\n",
      "0.819942857143\n",
      "0.82\n",
      "0.820514285714\n",
      "0.820514285714\n",
      "0.820285714286\n",
      "0.820228571429\n",
      "0.820228571429\n",
      "0.82\n",
      "0.820857142857\n",
      "0.820628571429\n",
      "0.821371428571\n",
      "0.820514285714\n",
      "0.821085714286\n",
      "0.820628571429\n",
      "0.8216\n",
      "0.821085714286\n",
      "0.821142857143\n",
      "0.8212\n",
      "0.821314285714\n",
      "0.821142857143\n",
      "0.821428571429\n",
      "0.822\n",
      "0.821257142857\n",
      "0.821371428571\n",
      "0.821485714286\n",
      "0.820742857143\n",
      "0.821314285714\n",
      "0.821771428571\n",
      "0.821828571429\n",
      "0.822571428571\n",
      "0.822057142857\n",
      "0.821714285714\n",
      "0.821714285714\n",
      "0.821428571429\n",
      "0.821657142857\n",
      "0.8212\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    X_train_mini, y_train_mini = X_train[0:2000], y_train[0:2000]\n",
    "    N = X_train_mini.shape[0]\n",
    "    int_w1 = result[4]\n",
    "    int_w2 = result[5]\n",
    "    int_theta1 = result[1]\n",
    "    int_theta2 = result[2]\n",
    "    int_theta3 = result[3]\n",
    "\n",
    "    result = gradient_descent(X_train_mini, y_train_mini, int_w1, int_w2, int_theta1, int_theta2, int_theta3, 0.00001, 0.0001, 10)\n",
    "    output = predict_accuracy(X_test, y_test, result[1], result[2], result[3], result[4], result[5])\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparray = np.array(result)\n",
    "np.save('result.npy', nparray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
