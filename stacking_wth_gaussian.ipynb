{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Import and Organise the data####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "mnist = fetch_mldata('MNIST original', data_home=\".\")\n",
    "mnist.data, mnist.target = shuffle(mnist.data, mnist.target)\n",
    "X = mnist.data\n",
    "y_float = mnist.target\n",
    "y_int = y_float.astype(np.int64)\n",
    "y = np.eye(10)[y_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "s_train = np.ones(X_train.shape[0])\n",
    "X_train = np.hstack((X_train, s_train.reshape(len(s_train),1)))\n",
    "s_test = np.ones(X_test.shape[0])\n",
    "X_test = np.hstack((X_test, s_test.reshape(len(s_test),1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## define useful functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(a):\n",
    "    return 1.0 / (1.0 + np.exp(-a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x, y, w1, w2, w3, theta1, theta2,theta3):\n",
    "    z1 = np.matmul(x, w1)\n",
    "    z2 = np.matmul(x, w2)\n",
    "    z3 = np.matmul(x, w3)\n",
    "    zf = np.matmul(z1, theta1) + np.matmul(z2, theta2)+np.matmul(z3, theta3)\n",
    "    sig = (sigmoid(zf)-y) # [N, 10]\n",
    "    gradient_c_theta1 = np.matmul(np.transpose(z1), sig) / N #[S1, N] [N, 10]\n",
    "    gradient_c_theta2 = np.matmul(np.transpose(z2), sig) / N #[S2, N] [N, 10]\n",
    "    gradient_c_theta3 = np.matmul(np.transpose(z3), sig) / N #[S3,N] [N,10]\n",
    "    gradient_c_z1 = np.matmul(theta1, np.transpose(sig))  / N #[S1, 10] [N, 10]\n",
    "    gradient_c_z2 = np.matmul(theta2, np.transpose(sig)) / N \n",
    "    gradient_c_z3 = np.matmul(theta3, np.transpose(sig)) / N\n",
    "    #gradient_z1_w1= np.tranpose(x).T[:,:,None]*np.transpose(np.multiply(sigmoid(z2), (1-sig(z2)))).T[:,None] #[N, S1, 780]\n",
    "    gradient_z1_w1 =x\n",
    "    gradient_c_w1 = np.matmul(np.transpose(x),np.transpose(gradient_c_z1))\n",
    "    gradient_z2_w2=np.ones((N,S2_logistic,785))\n",
    "    gradient_c_w2=np.ones((S2_logistic,785))\n",
    "    for i in range(S2_logistic):\n",
    "        siggy = np.multiply(sigmoid(z2),(1-sigmoid(z2))) ### [N,S2 ]\n",
    "        gradient_z2_w2[:,i,:] = x * (siggy[:,i].reshape(N,1))   ###[N,S2,785]\n",
    "    for i in range(S2_logistic):    \n",
    "        gradient_c_w2[i,:] =np.matmul(gradient_c_z1[i,:],gradient_z2_w2[:,i,:])\n",
    "    gradient_z3_w3=np.ones((N,S3_Gauss,785))\n",
    "    gradient_c_w3=np.ones((S3_Gauss,785))\n",
    "    for i in range(S3_Gauss):\n",
    "        gradient_z3_w3[:,i,:] = np.multiply((beta*(x-w3[:,i])), np.exp( beta*(np.linalg.norm(x-w3[:,i]))))   #[N, i ,785]\n",
    "    for i in range(S3_Gauss):\n",
    "        gradient_c_w3[i,:] =np.matmul(gradient_c_z1[i,:],gradient_z2_w2[:,i,:])\n",
    "        \n",
    "    return zf, gradient_c_theta1, gradient_c_theta2, gradient_c_theta3, gradient_c_w1, gradient_c_w2, gradient_c_w3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z1 = linear_output_z1(X_train, int_w1)\n",
    "# z2 = logistic_output_z2(X_train, int_w2)\n",
    "# zf = logistic_output(X_train, z1, z2, int_theta1, int_theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, int_w1, int_w2, int_w3, int_theta1, int_theta2, int_theta3, lowtrain, uptrain, iterations,N):\n",
    "\n",
    "    place_w1=int_w1\n",
    "    place_w2=int_w2\n",
    "    place_w3=int_w3\n",
    "    place_theta1=int_theta1\n",
    "    place_theta2=int_theta2\n",
    "    place_theta3=int_theta3\n",
    "\n",
    "    for i in range(iterations):\n",
    "        trainrate=np.random.uniform(lowtrain,uptrain,1)/np.cbrt(i+1) \n",
    "\n",
    "        zf, gradient_theta1, gradient_theta2, gradient_theta3, gradient_w1, gradient_w2, gradient_w3 = gradient(x, y, place_w1, place_w2, place_w3, place_theta1, place_theta2, place_theta3)\n",
    "        p = sigmoid(zf)\n",
    "            \n",
    "        place_w1 = place_w1 - (trainrate * gradient_w1) - (0.1/N)*place_w1 * trainrate\n",
    "        place_w2 = place_w2 - (trainrate * np.transpose(gradient_w2)) - (0.1/N)*place_w2 * trainrate\n",
    "        place_w3 = place_w3 - (trainrate * np.transpose(gradient_w3)) - (0.1/N)*place_w3 * trainrate\n",
    "\n",
    "        place_theta1 = place_theta1 - trainrate*gradient_theta1*0.1 - (0.1/N)*place_theta1 * trainrate \n",
    "        place_theta2 = place_theta2 - trainrate*gradient_theta2 - (0.1/N)*place_theta2 * trainrate\n",
    "        place_theta3 = place_theta3 - trainrate*gradient_theta3 - (0.1/N)*place_theta3 * trainrate\n",
    "\n",
    "    return  p, place_theta1, place_theta2, place_theta3, place_w1, place_w2, place_w3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_accuracy(xtest, ytest, theta1, theta2, theta3, w1, w2, w3):\n",
    "    z1 = np.matmul(xtest, w1)\n",
    "    z2 = np.matmul(xtest, w2)\n",
    "    z3 = np.matmul(xtest, w3) \n",
    "    zf = np.matmul(z1, theta1) + np.matmul(z2, theta2) + np.matmul(z3, theta3)\n",
    "    p = sigmoid(zf)\n",
    "    prediction = np.argmax(p, axis=1)\n",
    "    answer = np.argmax(ytest, axis=1)\n",
    "    success_rate = answer == prediction\n",
    "    success_rate = success_rate*1\n",
    "    prediction_rate = sum(success_rate) / xtest.shape[0]\n",
    "    \n",
    "    return prediction_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "S1_linear = 3\n",
    "S2_logistic = 3\n",
    "S3_Gauss = 3\n",
    "N=52500 # Batch size\n",
    "beta = 0.1\n",
    "\n",
    "int_w1, int_w2,int_w3 = np.random.uniform(-1,1,(X_train.shape[1],S1_linear)), np.random.uniform(-1,1,(X_train.shape[1], S2_logistic)), np.random.uniform(-1,1,(X_train.shape[1], S3_Gauss))\n",
    "int_theta1, int_theta2, int_theta3 = np.random.uniform(-1,1,(S1_linear,10)), np.random.uniform(-1,1,(S2_logistic,10)), np.random.uniform(-1,1,(S3_Gauss,10))\n",
    "result = gradient_descent(X_train, y_train, int_w1, int_w2, int_w3, int_theta1, int_theta2, int_theta3, 0.00001, 0.0001, 1,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0630285714286\n",
      "1 0.0586285714286\n",
      "2 0.0546285714286\n",
      "3 0.0547428571429\n",
      "4 0.0579428571429\n",
      "5 0.0584\n",
      "6 0.0605142857143\n",
      "7 0.0624\n",
      "8 0.0658857142857\n",
      "9 0.0672\n",
      "10 0.0687428571429\n",
      "11 0.0726285714286\n",
      "12 0.076\n",
      "13 0.0803428571429\n",
      "14 0.0854285714286\n",
      "15 0.0888571428571\n",
      "16 0.0924571428571\n",
      "17 0.0965714285714\n",
      "18 0.0992571428571\n",
      "19 0.102457142857\n",
      "20 0.105428571429\n",
      "21 0.108857142857\n",
      "22 0.110742857143\n",
      "23 0.114514285714\n",
      "24 0.116914285714\n",
      "25 0.12\n",
      "26 0.123657142857\n",
      "27 0.126285714286\n",
      "28 0.130514285714\n",
      "29 0.133942857143\n",
      "30 0.136914285714\n",
      "31 0.141314285714\n",
      "32 0.145257142857\n",
      "33 0.152171428571\n",
      "34 0.157371428571\n",
      "35 0.160171428571\n",
      "36 0.164571428571\n",
      "37 0.169028571429\n",
      "38 0.172171428571\n",
      "39 0.178057142857\n",
      "40 0.182171428571\n",
      "41 0.185942857143\n",
      "42 0.188742857143\n",
      "43 0.191371428571\n",
      "44 0.1932\n",
      "45 0.199485714286\n",
      "46 0.203028571429\n",
      "47 0.208742857143\n",
      "48 0.214114285714\n",
      "49 0.217771428571\n",
      "50 0.220914285714\n",
      "51 0.222742857143\n",
      "52 0.2232\n",
      "53 0.226228571429\n",
      "54 0.226114285714\n",
      "55 0.228228571429\n",
      "56 0.232628571429\n",
      "57 0.235028571429\n",
      "58 0.238857142857\n",
      "59 0.238742857143\n",
      "60 0.2428\n",
      "61 0.245428571429\n",
      "62 0.248057142857\n",
      "63 0.249542857143\n",
      "64 0.253257142857\n",
      "65 0.258228571429\n",
      "66 0.260514285714\n",
      "67 0.264228571429\n",
      "68 0.264857142857\n",
      "69 0.268114285714\n",
      "70 0.2704\n",
      "71 0.271942857143\n",
      "72 0.274228571429\n",
      "73 0.277257142857\n",
      "74 0.278685714286\n",
      "75 0.28\n",
      "76 0.282228571429\n",
      "77 0.2836\n",
      "78 0.285828571429\n",
      "79 0.2916\n",
      "80 0.290342857143\n",
      "81 0.290628571429\n",
      "82 0.291542857143\n",
      "83 0.291714285714\n",
      "84 0.292057142857\n",
      "85 0.296057142857\n",
      "86 0.2972\n",
      "87 0.297942857143\n",
      "88 0.296742857143\n",
      "89 0.298914285714\n",
      "90 0.301028571429\n",
      "91 0.3004\n",
      "92 0.301428571429\n",
      "93 0.303142857143\n",
      "94 0.306914285714\n",
      "95 0.308114285714\n",
      "96 0.308171428571\n",
      "97 0.309028571429\n",
      "98 0.309542857143\n",
      "99 0.308857142857\n",
      "100 0.310457142857\n",
      "101 0.312\n",
      "102 0.314514285714\n",
      "103 0.318342857143\n",
      "104 0.320114285714\n",
      "105 0.321771428571\n",
      "106 0.3232\n",
      "107 0.324171428571\n",
      "108 0.324514285714\n",
      "109 0.326914285714\n",
      "110 0.328\n",
      "111 0.326857142857\n",
      "112 0.327028571429\n",
      "113 0.3276\n",
      "114 0.330571428571\n",
      "115 0.331771428571\n",
      "116 0.327085714286\n",
      "117 0.327485714286\n",
      "118 0.326914285714\n",
      "119 0.326514285714\n",
      "120 0.330914285714\n",
      "121 0.330628571429\n",
      "122 0.328457142857\n",
      "123 0.329828571429\n",
      "124 0.330228571429\n",
      "125 0.335428571429\n",
      "126 0.335657142857\n",
      "127 0.336285714286\n",
      "128 0.334685714286\n",
      "129 0.337142857143\n",
      "130 0.336114285714\n",
      "131 0.3372\n",
      "132 0.338457142857\n",
      "133 0.337485714286\n",
      "134 0.335371428571\n",
      "135 0.338628571429\n",
      "136 0.336057142857\n",
      "137 0.3392\n",
      "138 0.338285714286\n",
      "139 0.338685714286\n",
      "140 0.341085714286\n",
      "141 0.3416\n",
      "142 0.344114285714\n",
      "143 0.3432\n",
      "144 0.345714285714\n",
      "145 0.344285714286\n",
      "146 0.346514285714\n",
      "147 0.345885714286\n",
      "148 0.344114285714\n",
      "149 0.344228571429\n",
      "150 0.341885714286\n",
      "151 0.341428571429\n",
      "152 0.342914285714\n",
      "153 0.343771428571\n",
      "154 0.34\n",
      "155 0.338742857143\n",
      "156 0.339657142857\n",
      "157 0.340685714286\n",
      "158 0.343828571429\n",
      "159 0.345771428571\n",
      "160 0.348628571429\n",
      "161 0.344114285714\n",
      "162 0.346514285714\n",
      "163 0.341714285714\n",
      "164 0.342857142857\n",
      "165 0.347542857143\n",
      "166 0.349257142857\n",
      "167 0.345085714286\n",
      "168 0.349714285714\n",
      "169 0.352514285714\n",
      "170 0.352628571429\n",
      "171 0.354114285714\n",
      "172 0.355371428571\n",
      "173 0.357371428571\n",
      "174 0.352628571429\n",
      "175 0.3512\n",
      "176 0.353085714286\n",
      "177 0.353314285714\n",
      "178 0.352914285714\n",
      "179 0.350457142857\n",
      "180 0.352742857143\n",
      "181 0.355257142857\n",
      "182 0.358114285714\n",
      "183 0.355142857143\n",
      "184 0.353942857143\n",
      "185 0.356285714286\n",
      "186 0.357085714286\n",
      "187 0.356971428571\n",
      "188 0.357657142857\n",
      "189 0.356057142857\n",
      "190 0.356457142857\n",
      "191 0.356571428571\n",
      "192 0.357657142857\n",
      "193 0.359085714286\n",
      "194 0.358514285714\n",
      "195 0.3592\n",
      "196 0.359542857143\n",
      "197 0.357542857143\n",
      "198 0.358514285714\n",
      "199 0.356228571429\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    X_train_mini, y_train_mini = X_train[0:200], y_train[0:200]\n",
    "    N = X_train_mini.shape[0]\n",
    "    w1 = result[4]\n",
    "    w2 = result[5]\n",
    "    w3 = result[6]\n",
    "    theta1 = result[1]\n",
    "    theta2 = result[2]\n",
    "    theta3 = result[3]\n",
    "\n",
    "    result = gradient_descent(X_train_mini, y_train_mini, w1, w2, w3, theta1, theta2, theta3, 0.00001, 0.00005, 5,N)\n",
    "    output = predict_accuracy(X_test, y_test, theta1, theta2, theta3, w1, w2, w3)\n",
    "    print(i, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
