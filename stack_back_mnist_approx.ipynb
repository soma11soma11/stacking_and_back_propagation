{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking and back propagation on Mnist APPROXIMATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy as np\n",
    "mnist = fetch_mldata('MNIST original', data_home=\".\")\n",
    "X = mnist.data\n",
    "s = np.ones(X.shape[0])\n",
    "X_1 = np.hstack((X, s.reshape(len(s),1)))\n",
    "y_float = mnist.target\n",
    "y_int = y_float.astype(np.int64)\n",
    "y = np.eye(10)[y_int]\n",
    "N = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_X = np.cbrt(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_output_z1(x, w1):\n",
    "    z1 = np.dot(x, w1) \n",
    "    return z1\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    sumsoft = e_x.sum(axis=1)\n",
    "    bottomsoft = 1 / sumsoft\n",
    "    return np.transpose(np.transpose(e_x) * bottomsoft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.33780812e-39,   1.00000000e+00,   2.07914352e-40,\n",
       "         4.01545701e-35,   1.17029499e-53,   4.09873470e-47,\n",
       "         9.23638215e-32,   1.57165235e-54,   2.97561975e-37,\n",
       "         2.00728313e-37])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoge = np.dot(new_X_1, np.transpose(initial_w2)) \n",
    "softmax(hoge)[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(theta, w1, w2, x, y):\n",
    "    x_1 = new_X_1\n",
    "    z1 = linear_output_z1(x_1, w1)\n",
    "    z2 = softmax(np.dot(x_1, np.transpose(w2)))\n",
    "    Z = np.c_[x, z1, z2, s]\n",
    "    zf = np.matmul(theta, np.transpose(Z))\n",
    "    p = softmax(zf)\n",
    "    ce =  np.multiply(np.transpose(y), np.log(p))\n",
    "    ce_sum = ce.sum() / -N\n",
    "    return ce_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_theta = np.random.uniform(-1,1,(10, X.shape[1]+12))\n",
    "initial_w1 = np.random.uniform(-1,1, X.shape[1]+1)\n",
    "initial_w2 = np.random.uniform(-1,1,(10, X.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125.34137607135844"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(initial_theta, initial_w1, initial_w2, new_X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_c_theta(theta, w1, w2, x, y, eps):\n",
    "    e = np.ones(initial_theta.shape) * eps\n",
    "    gradient = (cross_entropy(theta + e, w1, w2, new_X, y) - cross_entropy(theta, w1, w2, new_X, y)) / eps\n",
    "    return gradient\n",
    "\n",
    "# def gradient_c_w1(theta, w1, w2, x, y, eps):\n",
    "#     gradient = \n",
    "#     return gradient\n",
    "\n",
    "# def gradient_c_w2(theta, w1, w2, x, y, eps):\n",
    "#     gradient = \n",
    "#     return gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173.18867425373696"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_c_theta(initial_theta, initial_w1, initial_w2, X, y, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
